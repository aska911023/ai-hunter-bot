import time
import streamlit as st # å€Ÿç”¨ streamlit çš„ secrets è¯»å–åŠŸèƒ½
from supabase import create_client
from datetime import datetime
import hunter # å¼•ç”¨æˆ‘å€‘å¯«å¥½çš„çˆ¬èŸ²æ¨¡çµ„

# --- 1. è¨­å®šæ©Ÿå™¨äººåƒæ•¸ ---
# ä½ å¸Œæœ›å®ƒæœå°‹ä»€éº¼é—œéµå­—ï¼Ÿ
TARGET_KEYWORDS = [
    "best new ai tools 2025",
    "latest generative ai startups",
    "free ai coding assistants",
    "new text to video ai models"
]

# ä½ å¸Œæœ›å®ƒå¤šä¹…è·‘ä¸€æ¬¡ï¼Ÿ (å–®ä½ï¼šç§’)
# å»ºè­°è¨­å®š 24 å°æ™‚ (86400ç§’) æˆ– 12 å°æ™‚ (43200ç§’)
# æ¸¬è©¦æ™‚å¯ä»¥è¨­çŸ­ä¸€é»ï¼Œä¾‹å¦‚ 60 ç§’
INTERVAL = 43200 

# --- 2. åˆå§‹åŒ– Supabase ---
# ç‚ºäº†è®“é€™å€‹è…³æœ¬èƒ½ç¨ç«‹é‹ä½œï¼Œæˆ‘å€‘éœ€è¦é€™è£¡ä¹Ÿé€£ç·šä¸€æ¬¡
try:
    url = st.secrets["supabase"]["url"]
    key = st.secrets["supabase"]["key"]
    supabase = create_client(url, key)
    print("âœ… Bot connected to Supabase.")
except Exception as e:
    print("âŒ Bot failed to connect. Check secrets.toml.")
    exit()

def run_bot_cycle():
    print(f"\nğŸ¤– [Auto-Hunter] Waking up at {datetime.now().strftime('%H:%M:%S')}...")
    
    total_added = 0
    
    for query in TARGET_KEYWORDS:
        print(f"   ğŸ” Scouting sector: '{query}'...")
        
        # A. æœå°‹ (SERP)
        try:
            # æ¯æ¬¡é—œéµå­—åªæ‰¾å‰ 3 å€‹çµæœï¼Œé¿å…å¤ªè²ªå¿ƒè¢«å°é–
            raw_results = hunter.search_web(query, max_results=3)
        except Exception as e:
            print(f"      âš ï¸ Search error: {e}")
            continue

        # B. çˆ¬å–èˆ‡éæ¿¾ (Crawl & Filter)
        for res in raw_results:
            link = res['link']
            
            # [é‡è¦] æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨è³‡æ–™åº« (å»é‡è¤‡)
            # æˆ‘å€‘å»è³‡æ–™åº«æŸ¥ä¸€ä¸‹é€™å€‹ link æ˜¯å¦å·²ç¶“æœ‰äº†
            existing = supabase.table("ai_resources").select("id").eq("link", link).execute()
            
            if existing.data:
                print(f"      â­ï¸  Skipping (Already exists): {res['title'][:20]}...")
                continue
            
            # C. çˆ¬å–è©³ç´°è³‡æ–™
            print(f"      ğŸ•·ï¸  Crawling new target: {link}...")
            data = hunter.crawl_website(link)
            
            if data:
                # D. å¯«å…¥è³‡æ–™åº«
                new_resource = {
                    "title": data['title'],
                    "link": data['link'],
                    "summary": data['summary'],
                    "image_url": data['image_url'],
                    "category": "Explore",     # æ©Ÿå™¨äººæŠ“çš„ä¸€å¾‹å…ˆä¸Ÿ Explore
                    "sub_category": "Demos",   # æˆ–æ–°å»ºä¸€å€‹ "Auto-Crawled" åˆ†é¡
                    "country": "Global",
                    "tags": ["bot-hunter", "auto"],
                    "raw_data": {"source": "bot_v1", "query": query},
                    "created_at": datetime.now().isoformat()
                }
                
                try:
                    supabase.table("ai_resources").insert(new_resource).execute()
                    print(f"      âœ… CAPTURED: {data['title']}")
                    total_added += 1
                except Exception as e:
                    print(f"      âŒ Insert failed: {e}")
            
            # ä¼‘æ¯ä¸€ä¸‹ï¼Œç•¶å€‹æœ‰ç¦®è²Œçš„æ©Ÿå™¨äºº
            time.sleep(2)

    print(f"ğŸ’¤ Cycle finished. Added {total_added} new resources. Sleeping for {INTERVAL}s.")

# --- 3. ä¸»å¾ªç’° (Main Loop) ---
if __name__ == "__main__":
    print("ğŸš€ AI Hunter Bot initialized. Press Ctrl+C to stop.")
    
    while True:
        run_bot_cycle()
        time.sleep(INTERVAL)